import Constants from 'expo-constants';
import * as FileSystem from 'expo-file-system/legacy';

type GeminiRole = 'user' | 'model';

export type SupportedLanguageCode = 'en' | 'hi' | 'bn';

export interface DocumentAnalysisResult {
  summary: string;
  keyPoints: string[];
  actionRequired: string;
}

export interface GeminiChatTurn {
  role: GeminiRole;
  text: string;
}

const LANGUAGE_NAME: Record<SupportedLanguageCode, string> = {
  en: 'English',
  hi: 'Hindi',
  bn: 'Bengali',
};

const DEFAULT_MODEL = 'gemini-2.5-flash';

const DEFAULT_VISION_MODEL = 'gemini-3-flash-preview';

const getEnv = (key: string): string | undefined => {
  // Expo only auto-injects EXPO_PUBLIC_* into the client bundle.
  // We keep a fallback for non-Expo environments.
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const value = (process?.env as any)?.[key];
  if (typeof value === 'string' && value.trim().length > 0) return value.trim();
  return undefined;
};

const getApiKey = (): string | undefined => {
  const fromPublic = getEnv('EXPO_PUBLIC_GEMINI_API_KEY');
  if (fromPublic) return fromPublic;

  // Read from Expo config (injected via app.config.js -> extra)
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const extra: any = (Constants as any)?.expoConfig?.extra ?? (Constants as any)?.manifest?.extra;
  const fromExtra = typeof extra?.GEMINI_API_KEY === 'string' ? extra.GEMINI_API_KEY.trim() : undefined;
  if (fromExtra) return fromExtra;

  // Fallback for non-Expo environments
  return getEnv('GEMINI_API_KEY');
};

const getModel = (): string => {
  return getEnv('EXPO_PUBLIC_GEMINI_MODEL') ?? DEFAULT_MODEL;
};

const getVisionModel = (): string => {
  return getEnv('EXPO_PUBLIC_GEMINI_VISION_MODEL') ?? DEFAULT_VISION_MODEL;
};

const isSupportedLanguage = (lang: string): lang is SupportedLanguageCode => {
  return lang === 'en' || lang === 'hi' || lang === 'bn';
};

const coerceLanguage = (lang: string): SupportedLanguageCode => {
  return isSupportedLanguage(lang) ? lang : 'en';
};

const getImageMimeType = (fileNameOrUri: string, providedMimeType?: string): string => {
  if (providedMimeType && providedMimeType.trim().length > 0) return providedMimeType.trim();

  const lower = fileNameOrUri.toLowerCase();
  const extension = (lower.split('.').pop() || '').trim();
  switch (extension) {
    case 'jpg':
    case 'jpeg':
      return 'image/jpeg';
    case 'png':
      return 'image/png';
    case 'webp':
      return 'image/webp';
    default:
      return 'application/octet-stream';
  }
};

const fileToBase64 = async (uri: string): Promise<string> => {
  try {
    return await FileSystem.readAsStringAsync(uri, {
      encoding: 'base64',
    });
  } catch (error) {
    console.error('Error converting file to base64:', error);
    throw new Error('Failed to read image file');
  }
};

const buildSystemInstruction = (language: SupportedLanguageCode): string => {
  const languageName = LANGUAGE_NAME[language];

  return [
    `You are an AI assistant for farmers worldwide, with a strong focus on India.`,
    `Your scope is LIMITED to agriculture and farming.`,
    `Allowed topics include: crops, plants, seeds, soil health, irrigation, fertilizers and manures, pests and diseases, weed management, weather and climate impact on farming, farm machinery and tools, sustainable and organic practices, post-harvest handling and storage, basic market guidance, and government or institutional agricultural schemes.`,
    `Agriculture statistics and trends are IN SCOPE: "most grown crops", cropped area, production share, seasonal patterns, and typical state-wise crop dominance.`,
    `When the user's location is India (or not specified), prioritize Indian conditions, crops, seasons, climates, practices, and government schemes.`,
    `When the user's location is outside India, tailor advice to that country or region if information is available; otherwise, give general best-practice guidance and clearly state any limitations.`,
    `Always respond in ${languageName}.`,
    `If the user asks anything clearly outside agriculture or farming (such as personal matters, coding, entertainment, etc.), politely refuse and redirect the conversation back to farming by suggesting 2–3 relevant agriculture-related example questions. Do NOT answer off-topic requests.`,
    `IMPORTANT: Do NOT falsely label agriculture questions as off-topic. If the question is about crops/farming in any way, answer it.`,
    `When giving advice, ask 1–3 clarifying questions if necessary (for example: crop type, country/state/district, season, soil type, irrigation method, or observed symptoms).`,
    `Use plain text with clear line breaks. Use bullet points or numbered lists when helpful.`,
    `Do not invent exact facts, prices, policies, or news.`,
    `If asked for year-specific stats (e.g., "in 2025 which crop is farmed the most"), answer with best-effort general ranking and explain uncertainty. Ask whether they mean India overall or a specific state. Suggest authoritative sources for exact figures (DAC&FW, NSSO, Directorate of Economics & Statistics, state agri dept).`,
    `If asked for "latest news", real-time prices, or time-sensitive updates, clearly say you cannot access live data. Suggest reliable sources such as government agriculture departments, extension services, official market portals, or meteorological agencies (e.g., IMD for India), and then provide a general, non-time-sensitive overview if possible.`,
    `If you do not know an answer or lack sufficient information, say so clearly and explain what additional details are needed.`,
    `Do not cut off mid-sentence. If the response is long and must stop, end by asking the user to say "continue".`
  ].join(' ');
};

const toGeminiContents = (turns: GeminiChatTurn[]) => {
  return turns.map((t) => ({
    role: t.role,
    parts: [{ text: t.text }],
  }));
};

const callGemini = async (params: {
  apiKey: string;
  model: string;
  language: SupportedLanguageCode;
  turns: GeminiChatTurn[];
}): Promise<string> => {
  const { apiKey, model, language, turns } = params;

  const url = `https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(
    model
  )}:generateContent?key=${encodeURIComponent(apiKey)}`;

  const res = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      systemInstruction: {
        parts: [{ text: buildSystemInstruction(language) }],
      },
      contents: toGeminiContents(turns),
      generationConfig: {
        temperature: 0.3,
        topP: 0.85,
        maxOutputTokens: 2048,
      },
    }),
  });

  const json = await res.json().catch(() => ({}));

  if (!res.ok) {
    const message =
      typeof json?.error?.message === 'string'
        ? json.error.message
        : `Gemini request failed (${res.status})`;
    const error = new Error(message);
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    (error as any).status = res.status;
    throw error;
  }

  const text = json?.candidates?.[0]?.content?.parts
    ?.map((p: { text?: string }) => p.text)
    .filter(Boolean)
    .join('');

  if (typeof text === 'string' && text.trim().length > 0) return text.trim();
  throw new Error('Gemini returned an empty response');
};

export const getGeminiChatResponse = async (params: {
  userText: string;
  language: string;
  history: GeminiChatTurn[];
}): Promise<string> => {
  const apiKey = getApiKey();
  if (!apiKey) {
    throw new Error(
      'Missing Gemini API key. Set EXPO_PUBLIC_GEMINI_API_KEY in .env for Expo.'
    );
  }

  const language = coerceLanguage(params.language);

  // Keep prompt size in check: send last ~12 turns.
  const trimmedHistory = params.history.slice(-12);
  const turns: GeminiChatTurn[] = [...trimmedHistory, { role: 'user', text: params.userText }];

  const model = getModel();
  return await callGemini({ apiKey, model, language, turns });
};

// ============ DOCUMENT ANALYSIS VIA GEMINI VISION ============

export const isGeminiConfigured = (): boolean => {
  return !!getApiKey();
};

export const analyzeDocument = async (params: {
  fileUri: string;
  fileName: string;
  mimeType?: string;
  language?: string;
}): Promise<DocumentAnalysisResult> => {
  const { fileUri, fileName, mimeType, language = 'en' } = params;

  const apiKey = getApiKey();
  if (!apiKey) {
    throw new Error('Missing Gemini API key. Set GEMINI_API_KEY in .env file.');
  }

  const targetLanguage = coerceLanguage(language);
  const languageName = LANGUAGE_NAME[targetLanguage];
  const detectedMimeType = getImageMimeType(fileName || fileUri, mimeType);

  if (!detectedMimeType.startsWith('image/')) {
    throw new Error('Currently only image files (JPG, PNG, WEBP) are supported for analysis.');
  }

  const imageBase64 = await fileToBase64(fileUri);
  const model = getVisionModel();

  const url = `https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(
    model
  )}:generateContent?key=${encodeURIComponent(apiKey)}`;

  const prompt = `You are an expert document analyzer for farmers, especially in India.

IMPORTANT:
- Respond ONLY in ${languageName}.
- Respond as STRICT JSON only (no markdown, no extra text).
- The user provided an image of a document.

Your job:
1) Identify what the document is (e.g., loan notice, KCC, land record, insurance policy, mandi receipt, government scheme letter, fertilizer invoice, soil test report, etc.).
2) Extract the most important details farmers care about: dates, amounts, deadlines, reference numbers, names, crop/land details, bank/office names, and any required steps.
3) Give clear, practical next steps that help the farmer.

Return JSON exactly in this shape:
{
  "summary": "One clear paragraph (6-10 sentences) in ${languageName} that explains the entire document in simple terms for a farmer",
  "keyPoints": ["3-7 bullet-like points with specific details"],
  "actionRequired": "Clear action the farmer should take (with deadlines if present)"
}

If the image is unclear or not a document, still return JSON and ask for a clearer photo (good lighting, full page visible, no blur).`;

  const requestBody = {
    systemInstruction: {
      parts: [{ text: `Always respond in ${languageName}. Return JSON only.` }],
    },
    contents: [
      {
        role: 'user',
        parts: [
          {
            inlineData: {
              mimeType: detectedMimeType,
              data: imageBase64,
            },
          },
          { text: prompt },
        ],
      },
    ],
    generationConfig: {
      temperature: 0.2,
      topP: 0.85,
      maxOutputTokens: 2048,
    },
  };

  const res = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(requestBody),
  });

  const json = await res.json().catch(() => ({}));
  if (!res.ok) {
    const message =
      typeof json?.error?.message === 'string'
        ? json.error.message
        : `Gemini request failed (${res.status})`;
    throw new Error(message);
  }

  const contentText = json?.candidates?.[0]?.content?.parts
    ?.map((p: { text?: string }) => p.text)
    .filter(Boolean)
    .join('')
    ?.trim();

  if (!contentText) {
    throw new Error('No response received from Gemini');
  }

  try {
    const jsonMatch = contentText.match(/\{[\s\S]*\}/);
    const raw = jsonMatch ? jsonMatch[0] : contentText;
    const parsed = JSON.parse(raw);
    return {
      summary:
        typeof parsed?.summary === 'string' && parsed.summary.trim().length > 0
          ? parsed.summary.trim()
          : 'Unable to extract summary from the document.',
      keyPoints: Array.isArray(parsed?.keyPoints)
        ? parsed.keyPoints.map((x: unknown) => String(x))
        : ['No key points extracted'],
      actionRequired:
        typeof parsed?.actionRequired === 'string' && parsed.actionRequired.trim().length > 0
          ? parsed.actionRequired.trim()
          : 'No specific action required.',
    };
  } catch (parseError) {
    console.error('Error parsing Gemini response:', parseError);
    return {
      summary: contentText,
      keyPoints: ['Please upload a clearer image of the document (full page, good light, no blur).'],
      actionRequired: 'Upload a clearer document image for better analysis',
    };
  }
};

// ============ AUDIO TRANSCRIPTION VIA GEMINI ============
// This is Method 2: Send audio directly to Gemini instead of using a separate STT API
// Benefits: 1 API call, no extra rate limits, Gemini understands context better

/**
 * Determine MIME type from audio file URI
 */
const getAudioMimeType = (uri: string): string => {
  const ext = (uri.split('.').pop() || '').toLowerCase();
  switch (ext) {
    case 'm4a':
    case 'mp4':
    case 'aac':
      return 'audio/mp4';
    case 'webm':
      return 'audio/webm';
    case 'wav':
      return 'audio/wav';
    case 'mp3':
      return 'audio/mpeg';
    case 'ogg':
      return 'audio/ogg';
    case 'flac':
      return 'audio/flac';
    default:
      return 'audio/mp4'; // Default for mobile recordings
  }
};

/**
 * 
 * @param audioUri - Local file URI of the recorded audio
 * @param language - Target language for transcription (en, hi, bn)
 * @returns Transcribed text
 */
export const transcribeAudioWithGemini = async (params: {
  audioUri: string;
  language: string;
}): Promise<string> => {
  const { audioUri, language } = params;

  const apiKey = getApiKey();
  if (!apiKey) {
    throw new Error('Missing Gemini API key. Set GEMINI_API_KEY in .env file.');
  }

  const langCode = coerceLanguage(language);
  const languageName = LANGUAGE_NAME[langCode];

  console.log('Transcribing audio with Gemini:', audioUri);
  console.log('Target language:', languageName);

  // Read audio file as base64
  const audioBase64 = await FileSystem.readAsStringAsync(audioUri, {
    encoding: 'base64',
  });

  const mimeType = getAudioMimeType(audioUri);
  console.log('Audio MIME type:', mimeType);
  console.log('Audio base64 length:', audioBase64.length);

  const model = 'gemini-3-flash-preview';
  const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${encodeURIComponent(apiKey)}`;

  // Build request with audio inline data
  const requestBody = {
    contents: [
      {
        role: 'user',
        parts: [
          {
            inlineData: {
              mimeType: mimeType,
              data: audioBase64,
            },
          },
          {
            text: `Transcribe this audio. The speaker is likely speaking in ${languageName} (or possibly English, Hindi, or Bengali). 
            
            IMPORTANT RULES:
            1. Return ONLY the exact transcription of what was spoken - no explanations, no quotes, no prefixes like "The speaker said:"
            2. If the audio is in ${languageName}, transcribe in ${languageName}
            3. If the audio is unclear or empty, respond with exactly: [NO_SPEECH]
            4. Keep the transcription natural and conversational
            5. Do NOT translate - transcribe in the original spoken language
            
            Transcription:`,
          },
        ],
      },
    ],
    generationConfig: {
      temperature: 0.1, // Low temperature for accurate transcription
      maxOutputTokens: 1024,
    },
  };

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(requestBody),
  });

  console.log('Gemini transcription response status:', response.status);

  const json = await response.json().catch(() => ({}));

  if (!response.ok) {
    const errorMessage = json?.error?.message || `Gemini request failed (${response.status})`;
    console.error('Gemini transcription error:', json);

    // User-friendly error messages
    if (errorMessage.toLowerCase().includes('quota') || errorMessage.toLowerCase().includes('rate')) {
      throw new Error('Too many requests. Please wait a moment and try again.');
    }
    if (response.status === 400) {
      throw new Error('Audio format not supported. Please try again.');
    }

    throw new Error(errorMessage);
  }

  // Extract transcription from response
  const transcription = json?.candidates?.[0]?.content?.parts
    ?.map((p: { text?: string }) => p.text)
    .filter(Boolean)
    .join('')
    .trim();

  console.log('Raw transcription:', transcription);

  // Check for no speech
  if (!transcription || transcription === '[NO_SPEECH]' || transcription.includes('[NO_SPEECH]')) {
    throw new Error('No speech detected. Please speak clearly and try again.');
  }

  // Clean up any accidental prefixes Gemini might add
  let cleanTranscription = transcription
    .replace(/^(transcription:|the speaker said:|audio transcription:)/i, '')
    .replace(/^["']|["']$/g, '') // Remove surrounding quotes
    .trim();

  if (!cleanTranscription) {
    throw new Error('No speech detected. Please speak clearly and try again.');
  }

  console.log('Clean transcription:', cleanTranscription);
  return cleanTranscription;
};

// ============ CROP PREDICTION VIA GEMINI ============

export interface CropPredictionInput {
  cropType: string;
  acres: string;
  plantingDate: string;
  harvestDate: string;
  soilType: string;
  farmingMethod: string;
  additionalInfo: string;
  location: string;
}

export interface CropPredictionResult {
  expectedYield: string;
  cropHealth: string;
  riskLevel: string;
  waterRequirement: string;
  fertilizerSuggestion: string;
  harvestReadiness: string;
  recommendations: string;
}

/**
 * Get crop prediction from Gemini AI
 * @param input - Crop prediction input data
 * @param language - Target language for response (en, hi, bn)
 * @returns Crop prediction results
 */
export const getCropPrediction = async (params: {
  input: CropPredictionInput;
  language: string;
}): Promise<CropPredictionResult> => {
  const { input, language } = params;

  const apiKey = getApiKey();
  if (!apiKey) {
    throw new Error('Missing Gemini API key. Set GEMINI_API_KEY in .env file.');
  }

  const langCode = coerceLanguage(language);
  const languageName = LANGUAGE_NAME[langCode];

  const model = getModel(); // Uses gemini-2.5-flash as specified
  const url = `https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(
    model
  )}:generateContent?key=${encodeURIComponent(apiKey)}`;

  // Build detailed prompt for crop prediction
  const prompt = `You are an expert agricultural AI assistant specializing in crop yield prediction and farming advice for India.

FARMER'S CROP INFORMATION:
- Crop Type: ${input.cropType}
- Farm Size: ${input.acres} acres
- Planting Date: ${input.plantingDate}
- Expected Harvest Date: ${input.harvestDate}
- Soil Type: ${input.soilType}
- Farming Method: ${input.farmingMethod}
- Location: ${input.location}
${input.additionalInfo ? `- Additional Information: ${input.additionalInfo}` : ''}

IMPORTANT INSTRUCTIONS:
1. Respond ONLY in ${languageName}
2. Return STRICT JSON format only (no markdown, no extra text)
3. Base predictions on Indian agricultural conditions and practices
4. Consider the specific location's climate, rainfall patterns, and growing conditions
5. Provide practical, actionable recommendations

Analyze the above crop information and provide predictions in this EXACT JSON format:
{
  "expectedYield": "Estimated yield range in Quintals per acre (e.g., '18-22 Quintals/acre')",
  "cropHealth": "Overall health assessment (Excellent/Good/Fair/Poor)",
  "riskLevel": "Risk assessment (Low/Medium/High)",
  "waterRequirement": "Water needs assessment (Low/Medium/High)",
  "fertilizerSuggestion": "Recommended fertilizer type (e.g., 'Nitrogen-based', 'NPK 10:26:26', 'Organic compost')",
  "harvestReadiness": "Harvest timing assessment (Early/On Time/Delayed)",
  "recommendations": "2-3 specific, actionable recommendations for the farmer (as a single paragraph in ${languageName})"
}

Consider factors like:
- Typical yield for this crop in the specified location
- Soil compatibility with the crop
- Seasonal timing and climate conditions
- Farming method effectiveness
- Common risks and mitigation strategies`;

  const requestBody = {
    systemInstruction: {
      parts: [{
        text: `You are an expert agricultural AI for Indian farmers. Always respond in ${languageName}. Return JSON only.`
      }],
    },
    contents: [
      {
        role: 'user',
        parts: [{ text: prompt }],
      },
    ],
    generationConfig: {
      temperature: 0.3,
      topP: 0.85,
      maxOutputTokens: 2048,
    },
  };

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(requestBody),
  });

  const json = await response.json().catch(() => ({}));

  if (!response.ok) {
    const errorMessage = json?.error?.message || `Gemini request failed (${response.status})`;
    console.error('Gemini crop prediction error:', json);
    throw new Error(errorMessage);
  }

  const contentText = json?.candidates?.[0]?.content?.parts
    ?.map((p: { text?: string }) => p.text)
    .filter(Boolean)
    .join('')
    ?.trim();

  if (!contentText) {
    throw new Error('No response received from Gemini');
  }

  try {
    // Extract JSON from response (handle markdown code blocks if present)
    const jsonMatch = contentText.match(/\{[\s\S]*\}/);
    const raw = jsonMatch ? jsonMatch[0] : contentText;
    const parsed = JSON.parse(raw);

    return {
      expectedYield: parsed?.expectedYield || 'Not available',
      cropHealth: parsed?.cropHealth || 'Good',
      riskLevel: parsed?.riskLevel || 'Medium',
      waterRequirement: parsed?.waterRequirement || 'Medium',
      fertilizerSuggestion: parsed?.fertilizerSuggestion || 'Consult local expert',
      harvestReadiness: parsed?.harvestReadiness || 'On Time',
      recommendations: parsed?.recommendations || 'Follow standard farming practices for your crop and region.',
    };
  } catch (parseError) {
    console.error('Error parsing Gemini prediction response:', parseError);
    throw new Error('Failed to parse prediction results. Please try again.');
  }
};
